{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Wavenumber.ipynb","provenance":[],"authorship_tag":"ABX9TyM31hHaSmw9dAWdzdE6LTc9"},"kernelspec":{"name":"python37664bitbemppcondae52aef22021a4bb9aca28cb07a52349e","display_name":"Python 3.7.6 64-bit ('bempp': conda)"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"YwDniIKJjg8q","colab_type":"code","colab":{}},"source":["import dask.dataframe as dd\n","df = dd.read_csv(\"../VoxelsDataset/wavenumberVoxels/*\").compute().iloc[:, 2:]\n","df.head()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":"        index   feature_1   feature_2   feature_3   feature_4   feature_5  \\\n0 -117.413551 -117.414613 -117.417829 -117.423202 -117.430734 -117.440428   \n1 -113.881322 -113.882395 -113.885622 -113.891006 -113.898548 -113.908253   \n2 -123.985723 -123.986806 -123.990043 -123.995437 -124.002989 -124.012704   \n3 -114.424147 -114.425230 -114.428468 -114.433861 -114.441414 -114.451129   \n4 -131.450275 -131.451352 -131.454583 -131.459971 -131.467517 -131.477226   \n\n    feature_6   feature_7   feature_8   feature_9  ...   1321   1322   1323  \\\n0 -117.452289 -117.466324 -117.482539 -117.500943  ...  False  False  False   \n1 -113.920126 -113.934171 -113.950398 -113.968812  ...  False  False  False   \n2 -124.024586 -124.038642 -124.054878 -124.073302  ...  False  False  False   \n3 -114.463012 -114.477068 -114.493304 -114.511729  ...  False  False  False   \n4 -131.489102 -131.503152 -131.519382 -131.537801  ...  False  False  False   \n\n    1324   1325   1326   1327   1328   1329   1330  \n0  False  False  False  False  False  False  False  \n1  False  False  False  False  False  False  False  \n2  False  False  False  False  False  False  False  \n3  False  False  False  False  False  False  False  \n4  False  False  False  False  False  False   True  \n\n[5 rows x 1732 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>...</th>\n      <th>1321</th>\n      <th>1322</th>\n      <th>1323</th>\n      <th>1324</th>\n      <th>1325</th>\n      <th>1326</th>\n      <th>1327</th>\n      <th>1328</th>\n      <th>1329</th>\n      <th>1330</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-117.413551</td>\n      <td>-117.414613</td>\n      <td>-117.417829</td>\n      <td>-117.423202</td>\n      <td>-117.430734</td>\n      <td>-117.440428</td>\n      <td>-117.452289</td>\n      <td>-117.466324</td>\n      <td>-117.482539</td>\n      <td>-117.500943</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-113.881322</td>\n      <td>-113.882395</td>\n      <td>-113.885622</td>\n      <td>-113.891006</td>\n      <td>-113.898548</td>\n      <td>-113.908253</td>\n      <td>-113.920126</td>\n      <td>-113.934171</td>\n      <td>-113.950398</td>\n      <td>-113.968812</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-123.985723</td>\n      <td>-123.986806</td>\n      <td>-123.990043</td>\n      <td>-123.995437</td>\n      <td>-124.002989</td>\n      <td>-124.012704</td>\n      <td>-124.024586</td>\n      <td>-124.038642</td>\n      <td>-124.054878</td>\n      <td>-124.073302</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-114.424147</td>\n      <td>-114.425230</td>\n      <td>-114.428468</td>\n      <td>-114.433861</td>\n      <td>-114.441414</td>\n      <td>-114.451129</td>\n      <td>-114.463012</td>\n      <td>-114.477068</td>\n      <td>-114.493304</td>\n      <td>-114.511729</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-131.450275</td>\n      <td>-131.451352</td>\n      <td>-131.454583</td>\n      <td>-131.459971</td>\n      <td>-131.467517</td>\n      <td>-131.477226</td>\n      <td>-131.489102</td>\n      <td>-131.503152</td>\n      <td>-131.519382</td>\n      <td>-131.537801</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 1732 columns</p>\n</div>"},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"3a7VG58zkSUG","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X = df.iloc[:,:401]\n","Y = df.iloc[:,401:]\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state = 42)\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.7, random_state = 42)\n",""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ks0qT7Tokmk7","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n","\n","ss = StandardScaler()\n","x_train = ss.fit_transform(x_train)\n","x_val = ss.transform(x_val)\n","x_test = ss.transform(x_test)\n",""],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDXtZh5rkt_V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"489b9100-d39e-490a-b926-39ee22b3ac06","executionInfo":{"status":"ok","timestamp":1581352626628,"user_tz":0,"elapsed":380,"user":{"displayName":"Jamie Barker","photoUrl":"","userId":"15698419684262383804"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from keras.optimizers import SGD, Adam\n","\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=50, verbose=1,)\n","early_stop = EarlyStopping(monitor='val_loss', patience=61, verbose=1, restore_best_weights=True)\n","opt = Adam()\n","\n","model = Sequential()\n","model.add(Dense(1000, input_dim=401, kernel_initializer='normal', activation='relu'))\n","model.add(Dense(500, kernel_initializer='normal', activation='relu'))\n","model.add(Dense(1331, kernel_initializer='normal', activation='sigmoid'))\n","# Compile model\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'], )\n","model.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, 1000)              402000    \n_________________________________________________________________\ndense_8 (Dense)              (None, 500)               500500    \n_________________________________________________________________\ndense_9 (Dense)              (None, 1331)              666831    \n=================================================================\nTotal params: 1,569,331\nTrainable params: 1,569,331\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"cell_type":"code","metadata":{"id":"XGspsh-PkzvH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"11d4709a-d8d7-47a4-bece-fc96dbeb6c46","executionInfo":{"status":"ok","timestamp":1581356253096,"user_tz":0,"elapsed":3624538,"user":{"displayName":"Jamie Barker","photoUrl":"","userId":"15698419684262383804"}},"tags":["outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend","outputPrepend"]},"source":["history = model.fit(x=x_train, y=y_train, validation_data = (x_val, y_val), epochs=1000, verbose=1, callbacks=[early_stop, reduce_lr])"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":"=========] - 1s 593us/step - loss: 0.0982 - accuracy: 0.9562 - val_loss: 0.0931 - val_accuracy: 0.9589\nEpoch 496/1000\n1523/1523 [==============================] - 1s 577us/step - loss: 0.0979 - accuracy: 0.9563 - val_loss: 0.0999 - val_accuracy: 0.9550\nEpoch 497/1000\n1523/1523 [==============================] - 1s 572us/step - loss: 0.0956 - accuracy: 0.9577 - val_loss: 0.1098 - val_accuracy: 0.9495\nEpoch 498/1000\n1523/1523 [==============================] - 1s 596us/step - loss: 0.0982 - accuracy: 0.9560 - val_loss: 0.0943 - val_accuracy: 0.9590\nEpoch 499/1000\n1523/1523 [==============================] - 1s 826us/step - loss: 0.0930 - accuracy: 0.9588 - val_loss: 0.1080 - val_accuracy: 0.9516\nEpoch 500/1000\n1523/1523 [==============================] - 1s 660us/step - loss: 0.0988 - accuracy: 0.9566 - val_loss: 0.0937 - val_accuracy: 0.9583\nEpoch 501/1000\n1523/1523 [==============================] - 1s 601us/step - loss: 0.0963 - accuracy: 0.9576 - val_loss: 0.0946 - val_accuracy: 0.9586\nEpoch 502/1000\n1523/1523 [==============================] - 1s 628us/step - loss: 0.0952 - accuracy: 0.9575 - val_loss: 0.1063 - val_accuracy: 0.9512\nEpoch 503/1000\n1523/1523 [==============================] - 1s 601us/step - loss: 0.0966 - accuracy: 0.9568 - val_loss: 0.0959 - val_accuracy: 0.9568\nEpoch 504/1000\n1523/1523 [==============================] - 1s 573us/step - loss: 0.0945 - accuracy: 0.9581 - val_loss: 0.0939 - val_accuracy: 0.9579\nEpoch 505/1000\n1523/1523 [==============================] - 1s 570us/step - loss: 0.0940 - accuracy: 0.9582 - val_loss: 0.0930 - val_accuracy: 0.9586\nEpoch 506/1000\n1523/1523 [==============================] - 1s 585us/step - loss: 0.0945 - accuracy: 0.9582 - val_loss: 0.1037 - val_accuracy: 0.9546\nEpoch 507/1000\n1523/1523 [==============================] - 1s 614us/step - loss: 0.0948 - accuracy: 0.9577 - val_loss: 0.0997 - val_accuracy: 0.9557\nEpoch 508/1000\n1523/1523 [==============================] - 1s 600us/step - loss: 0.0941 - accuracy: 0.9585 - val_loss: 0.1002 - val_accuracy: 0.9550\nEpoch 509/1000\n1523/1523 [==============================] - 1s 601us/step - loss: 0.0984 - accuracy: 0.9564 - val_loss: 0.1074 - val_accuracy: 0.9518\nEpoch 510/1000\n1523/1523 [==============================] - 1s 660us/step - loss: 0.0967 - accuracy: 0.9577 - val_loss: 0.0950 - val_accuracy: 0.9585\nEpoch 511/1000\n1523/1523 [==============================] - 1s 722us/step - loss: 0.0937 - accuracy: 0.9585 - val_loss: 0.1050 - val_accuracy: 0.9542\nEpoch 512/1000\n1523/1523 [==============================] - 1s 561us/step - loss: 0.0968 - accuracy: 0.9568 - val_loss: 0.0936 - val_accuracy: 0.9587\nEpoch 513/1000\n1523/1523 [==============================] - 1s 584us/step - loss: 0.0942 - accuracy: 0.9581 - val_loss: 0.1006 - val_accuracy: 0.9547\n\nEpoch 00513: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\nEpoch 514/1000\n1523/1523 [==============================] - 1s 580us/step - loss: 0.0934 - accuracy: 0.9585 - val_loss: 0.0942 - val_accuracy: 0.9579\nEpoch 515/1000\n1523/1523 [==============================] - 1s 581us/step - loss: 0.0928 - accuracy: 0.9588 - val_loss: 0.0950 - val_accuracy: 0.9577\nEpoch 516/1000\n1523/1523 [==============================] - 1s 584us/step - loss: 0.0943 - accuracy: 0.9578 - val_loss: 0.0944 - val_accuracy: 0.9578\nEpoch 517/1000\n1523/1523 [==============================] - 1s 600us/step - loss: 0.0933 - accuracy: 0.9581 - val_loss: 0.0942 - val_accuracy: 0.9579\nEpoch 518/1000\n1523/1523 [==============================] - 1s 563us/step - loss: 0.0914 - accuracy: 0.9596 - val_loss: 0.1013 - val_accuracy: 0.9566\nEpoch 519/1000\n1523/1523 [==============================] - 1s 617us/step - loss: 0.0930 - accuracy: 0.9591 - val_loss: 0.0929 - val_accuracy: 0.9588\nEpoch 520/1000\n1523/1523 [==============================] - 1s 580us/step - loss: 0.0939 - accuracy: 0.9587 - val_loss: 0.0953 - val_accuracy: 0.9576\nEpoch 521/1000\n1523/1523 [==============================] - 1s 595us/step - loss: 0.0932 - accuracy: 0.9586 - val_loss: 0.0950 - val_accuracy: 0.9570\nEpoch 522/1000\n1523/1523 [==============================] - 1s 609us/step - loss: 0.0947 - accuracy: 0.9581 - val_loss: 0.0944 - val_accuracy: 0.9572\nEpoch 523/1000\n1523/1523 [==============================] - 1s 640us/step - loss: 0.0927 - accuracy: 0.9585 - val_loss: 0.0921 - val_accuracy: 0.9597\nEpoch 524/1000\n1523/1523 [==============================] - 1s 618us/step - loss: 0.0938 - accuracy: 0.9583 - val_loss: 0.0937 - val_accuracy: 0.9593\nEpoch 525/1000\n1523/1523 [==============================] - 1s 585us/step - loss: 0.0937 - accuracy: 0.9584 - val_loss: 0.1013 - val_accuracy: 0.9540\nEpoch 526/1000\n1523/1523 [==============================] - 1s 601us/step - loss: 0.0936 - accuracy: 0.9582 - val_loss: 0.0935 - val_accuracy: 0.9591\nEpoch 527/1000\n1523/1523 [==============================] - 1s 564us/step - loss: 0.0921 - accuracy: 0.9592 - val_loss: 0.0926 - val_accuracy: 0.9589\nEpoch 528/1000\n1523/1523 [==============================] - 1s 584us/step - loss: 0.0939 - accuracy: 0.9585 - val_loss: 0.0942 - val_accuracy: 0.9574\nEpoch 529/1000\n1523/1523 [==============================] - 1s 590us/step - loss: 0.0937 - accuracy: 0.9586 - val_loss: 0.0925 - val_accuracy: 0.9597\nEpoch 530/1000\n1523/1523 [==============================] - 1s 606us/step - loss: 0.0924 - accuracy: 0.9590 - val_loss: 0.0942 - val_accuracy: 0.9572\nEpoch 531/1000\n1523/1523 [==============================] - 1s 624us/step - loss: 0.0937 - accuracy: 0.9588 - val_loss: 0.1002 - val_accuracy: 0.9549\nEpoch 532/1000\n1523/1523 [==============================] - 1s 614us/step - loss: 0.0937 - accuracy: 0.9580 - val_loss: 0.1052 - val_accuracy: 0.9515\nEpoch 533/1000\n1523/1523 [==============================] - 1s 677us/step - loss: 0.0939 - accuracy: 0.9585 - val_loss: 0.0929 - val_accuracy: 0.9585\nEpoch 534/1000\n1523/1523 [==============================] - 1s 656us/step - loss: 0.0934 - accuracy: 0.9579 - val_loss: 0.1059 - val_accuracy: 0.9506\nEpoch 535/1000\n1523/1523 [==============================] - 1s 585us/step - loss: 0.0979 - accuracy: 0.9563 - val_loss: 0.0971 - val_accuracy: 0.9561\nEpoch 536/1000\n1523/1523 [==============================] - 1s 597us/step - loss: 0.0946 - accuracy: 0.9578 - val_loss: 0.0928 - val_accuracy: 0.9593\nEpoch 537/1000\n1523/1523 [==============================] - 1s 606us/step - loss: 0.0926 - accuracy: 0.9587 - val_loss: 0.0929 - val_accuracy: 0.9597\nEpoch 538/1000\n1523/1523 [==============================] - 1s 619us/step - loss: 0.0970 - accuracy: 0.9567 - val_loss: 0.0928 - val_accuracy: 0.9591\nEpoch 539/1000\n1523/1523 [==============================] - 1s 614us/step - loss: 0.0928 - accuracy: 0.9594 - val_loss: 0.0956 - val_accuracy: 0.9579\nEpoch 540/1000\n1523/1523 [==============================] - 1s 573us/step - loss: 0.0930 - accuracy: 0.9586 - val_loss: 0.0940 - val_accuracy: 0.9585\nEpoch 541/1000\n1523/1523 [==============================] - 1s 590us/step - loss: 0.0942 - accuracy: 0.9582 - val_loss: 0.0993 - val_accuracy: 0.9566\nEpoch 542/1000\n1523/1523 [==============================] - 1s 605us/step - loss: 0.0937 - accuracy: 0.9588 - val_loss: 0.0938 - val_accuracy: 0.9583\nEpoch 543/1000\n1523/1523 [==============================] - 1s 577us/step - loss: 0.0936 - accuracy: 0.9587 - val_loss: 0.1036 - val_accuracy: 0.9534\nEpoch 544/1000\n1523/1523 [==============================] - 1s 561us/step - loss: 0.0940 - accuracy: 0.9583 - val_loss: 0.0952 - val_accuracy: 0.9576\nEpoch 545/1000\n1523/1523 [==============================] - 1s 564us/step - loss: 0.0924 - accuracy: 0.9585 - val_loss: 0.0990 - val_accuracy: 0.9549\nEpoch 546/1000\n1523/1523 [==============================] - 1s 611us/step - loss: 0.0933 - accuracy: 0.9584 - val_loss: 0.0937 - val_accuracy: 0.9592\nEpoch 547/1000\n1523/1523 [==============================] - 1s 633us/step - loss: 0.0923 - accuracy: 0.9594 - val_loss: 0.0941 - val_accuracy: 0.9582\nEpoch 548/1000\n1523/1523 [==============================] - 1s 585us/step - loss: 0.0926 - accuracy: 0.9585 - val_loss: 0.0928 - val_accuracy: 0.9596\nEpoch 549/1000\n1523/1523 [==============================] - 1s 589us/step - loss: 0.0917 - accuracy: 0.9597 - val_loss: 0.0970 - val_accuracy: 0.9564\nEpoch 550/1000\n1523/1523 [==============================] - 1s 610us/step - loss: 0.0929 - accuracy: 0.9589 - val_loss: 0.1092 - val_accuracy: 0.9540\nEpoch 551/1000\n1523/1523 [==============================] - 1s 609us/step - loss: 0.0992 - accuracy: 0.9563 - val_loss: 0.0943 - val_accuracy: 0.9586\nEpoch 552/1000\n1523/1523 [==============================] - 1s 577us/step - loss: 0.0943 - accuracy: 0.9578 - val_loss: 0.0957 - val_accuracy: 0.9576\nEpoch 553/1000\n1523/1523 [==============================] - 1s 567us/step - loss: 0.0947 - accuracy: 0.9578 - val_loss: 0.0957 - val_accuracy: 0.9577\nEpoch 554/1000\n1523/1523 [==============================] - 1s 581us/step - loss: 0.0927 - accuracy: 0.9588 - val_loss: 0.0976 - val_accuracy: 0.9567\nEpoch 555/1000\n1523/1523 [==============================] - 1s 594us/step - loss: 0.0942 - accuracy: 0.9582 - val_loss: 0.0939 - val_accuracy: 0.9579\nEpoch 556/1000\n1523/1523 [==============================] - 1s 586us/step - loss: 0.0932 - accuracy: 0.9586 - val_loss: 0.0931 - val_accuracy: 0.9599\nEpoch 557/1000\n1523/1523 [==============================] - 1s 582us/step - loss: 0.0921 - accuracy: 0.9588 - val_loss: 0.0932 - val_accuracy: 0.9587\nEpoch 558/1000\n1523/1523 [==============================] - 1s 628us/step - loss: 0.0923 - accuracy: 0.9591 - val_loss: 0.0950 - val_accuracy: 0.9571\nEpoch 559/1000\n1523/1523 [==============================] - 1s 605us/step - loss: 0.0919 - accuracy: 0.9591 - val_loss: 0.0923 - val_accuracy: 0.9599\nEpoch 560/1000\n1523/1523 [==============================] - 1s 592us/step - loss: 0.0928 - accuracy: 0.9585 - val_loss: 0.1024 - val_accuracy: 0.9535\nEpoch 561/1000\n1523/1523 [==============================] - 1s 575us/step - loss: 0.0978 - accuracy: 0.9563 - val_loss: 0.0918 - val_accuracy: 0.9600\nEpoch 562/1000\n1523/1523 [==============================] - 1s 581us/step - loss: 0.0913 - accuracy: 0.9599 - val_loss: 0.0929 - val_accuracy: 0.9601\nEpoch 563/1000\n1523/1523 [==============================] - 1s 599us/step - loss: 0.0933 - accuracy: 0.9584 - val_loss: 0.0968 - val_accuracy: 0.9566\nEpoch 564/1000\n1523/1523 [==============================] - 1s 598us/step - loss: 0.0936 - accuracy: 0.9579 - val_loss: 0.0924 - val_accuracy: 0.9594\nEpoch 565/1000\n1523/1523 [==============================] - 1s 583us/step - loss: 0.0925 - accuracy: 0.9593 - val_loss: 0.0913 - val_accuracy: 0.9605\nEpoch 566/1000\n1523/1523 [==============================] - 1s 580us/step - loss: 0.0948 - accuracy: 0.9577 - val_loss: 0.0926 - val_accuracy: 0.9595\nEpoch 567/1000\n1523/1523 [==============================] - 1s 581us/step - loss: 0.0937 - accuracy: 0.9586 - val_loss: 0.0937 - val_accuracy: 0.9577\nEpoch 568/1000\n1523/1523 [==============================] - 1s 592us/step - loss: 0.0915 - accuracy: 0.9595 - val_loss: 0.0930 - val_accuracy: 0.9601\nEpoch 569/1000\n1523/1523 [==============================] - 1s 579us/step - loss: 0.0929 - accuracy: 0.9588 - val_loss: 0.0949 - val_accuracy: 0.9592\nEpoch 570/1000\n1523/1523 [==============================] - 1s 602us/step - loss: 0.0932 - accuracy: 0.9582 - val_loss: 0.0915 - val_accuracy: 0.9597\nEpoch 571/1000\n1523/1523 [==============================] - 1s 571us/step - loss: 0.0980 - accuracy: 0.9565 - val_loss: 0.0932 - val_accuracy: 0.9586\nEpoch 572/1000\n1523/1523 [==============================] - 1s 580us/step - loss: 0.0931 - accuracy: 0.9585 - val_loss: 0.0944 - val_accuracy: 0.9580\nEpoch 573/1000\n1523/1523 [==============================] - 1s 604us/step - loss: 0.0936 - accuracy: 0.9584 - val_loss: 0.1000 - val_accuracy: 0.9548\nEpoch 574/1000\n1523/1523 [==============================] - 1s 570us/step - loss: 0.0917 - accuracy: 0.9596 - val_loss: 0.0919 - val_accuracy: 0.9597\nEpoch 575/1000\n1523/1523 [==============================] - 1s 603us/step - loss: 0.0924 - accuracy: 0.9588 - val_loss: 0.0945 - val_accuracy: 0.9581\nEpoch 576/1000\n1523/1523 [==============================] - 1s 571us/step - loss: 0.0928 - accuracy: 0.9591 - val_loss: 0.0945 - val_accuracy: 0.9580\nEpoch 577/1000\n1523/1523 [==============================] - 1s 581us/step - loss: 0.0958 - accuracy: 0.9574 - val_loss: 0.0954 - val_accuracy: 0.9571\nEpoch 578/1000\n1523/1523 [==============================] - 1s 593us/step - loss: 0.0928 - accuracy: 0.9585 - val_loss: 0.0988 - val_accuracy: 0.9567\nEpoch 579/1000\n1523/1523 [==============================] - 1s 615us/step - loss: 0.0921 - accuracy: 0.9588 - val_loss: 0.0938 - val_accuracy: 0.9583\nEpoch 580/1000\n1523/1523 [==============================] - 1s 597us/step - loss: 0.0928 - accuracy: 0.9584 - val_loss: 0.0923 - val_accuracy: 0.9602\nEpoch 581/1000\n1523/1523 [==============================] - 1s 559us/step - loss: 0.0922 - accuracy: 0.9594 - val_loss: 0.0957 - val_accuracy: 0.9568\nEpoch 582/1000\n1523/1523 [==============================] - 1s 583us/step - loss: 0.0923 - accuracy: 0.9586 - val_loss: 0.0952 - val_accuracy: 0.9573\nEpoch 583/1000\n1523/1523 [==============================] - 1s 571us/step - loss: 0.0914 - accuracy: 0.9598 - val_loss: 0.0954 - val_accuracy: 0.9578\nEpoch 584/1000\n1523/1523 [==============================] - 1s 594us/step - loss: 0.0944 - accuracy: 0.9573 - val_loss: 0.1025 - val_accuracy: 0.9540\nEpoch 585/1000\n1523/1523 [==============================] - 1s 615us/step - loss: 0.0939 - accuracy: 0.9582 - val_loss: 0.0936 - val_accuracy: 0.9598\nEpoch 586/1000\n1523/1523 [==============================] - 1s 579us/step - loss: 0.0931 - accuracy: 0.9585 - val_loss: 0.0999 - val_accuracy: 0.9555\nEpoch 587/1000\n1523/1523 [==============================] - 1s 585us/step - loss: 0.0922 - accuracy: 0.9588 - val_loss: 0.0934 - val_accuracy: 0.9592\nEpoch 588/1000\n1523/1523 [==============================] - 1s 583us/step - loss: 0.0928 - accuracy: 0.9584 - val_loss: 0.0958 - val_accuracy: 0.9564\nEpoch 589/1000\n1523/1523 [==============================] - 1s 585us/step - loss: 0.0934 - accuracy: 0.9581 - val_loss: 0.0921 - val_accuracy: 0.9596\nEpoch 590/1000\n1523/1523 [==============================] - 1s 587us/step - loss: 0.0930 - accuracy: 0.9583 - val_loss: 0.0954 - val_accuracy: 0.9588\nEpoch 591/1000\n1523/1523 [==============================] - 1s 658us/step - loss: 0.0922 - accuracy: 0.9589 - val_loss: 0.0932 - val_accuracy: 0.9594\nEpoch 592/1000\n1523/1523 [==============================] - 1s 665us/step - loss: 0.0921 - accuracy: 0.9589 - val_loss: 0.1030 - val_accuracy: 0.9533\nEpoch 593/1000\n1523/1523 [==============================] - 1s 592us/step - loss: 0.0919 - accuracy: 0.9595 - val_loss: 0.0927 - val_accuracy: 0.9591\nEpoch 594/1000\n1523/1523 [==============================] - 1s 600us/step - loss: 0.0924 - accuracy: 0.9589 - val_loss: 0.0970 - val_accuracy: 0.9583\nEpoch 595/1000\n1523/1523 [==============================] - 1s 568us/step - loss: 0.0941 - accuracy: 0.9579 - val_loss: 0.0939 - val_accuracy: 0.9582\nEpoch 596/1000\n1523/1523 [==============================] - 1s 599us/step - loss: 0.0934 - accuracy: 0.9584 - val_loss: 0.0962 - val_accuracy: 0.9560\nEpoch 597/1000\n1523/1523 [==============================] - 1s 611us/step - loss: 0.0930 - accuracy: 0.9585 - val_loss: 0.0920 - val_accuracy: 0.9593\nEpoch 598/1000\n1523/1523 [==============================] - 1s 576us/step - loss: 0.0930 - accuracy: 0.9584 - val_loss: 0.0923 - val_accuracy: 0.9597\nEpoch 599/1000\n1523/1523 [==============================] - 1s 594us/step - loss: 0.0927 - accuracy: 0.9586 - val_loss: 0.0918 - val_accuracy: 0.9605\nEpoch 600/1000\n1523/1523 [==============================] - 1s 611us/step - loss: 0.0918 - accuracy: 0.9590 - val_loss: 0.0925 - val_accuracy: 0.9603\nEpoch 601/1000\n1523/1523 [==============================] - 1s 600us/step - loss: 0.0922 - accuracy: 0.9596 - val_loss: 0.0938 - val_accuracy: 0.9585\nEpoch 602/1000\n1523/1523 [==============================] - 1s 571us/step - loss: 0.0933 - accuracy: 0.9585 - val_loss: 0.0930 - val_accuracy: 0.9590\nEpoch 603/1000\n1523/1523 [==============================] - 1s 579us/step - loss: 0.0956 - accuracy: 0.9574 - val_loss: 0.0932 - val_accuracy: 0.9590\nEpoch 604/1000\n1523/1523 [==============================] - 1s 596us/step - loss: 0.0913 - accuracy: 0.9593 - val_loss: 0.0933 - val_accuracy: 0.9583\nEpoch 605/1000\n1523/1523 [==============================] - 1s 615us/step - loss: 0.0912 - accuracy: 0.9593 - val_loss: 0.0973 - val_accuracy: 0.9564\nEpoch 606/1000\n1523/1523 [==============================] - 1s 592us/step - loss: 0.0958 - accuracy: 0.9575 - val_loss: 0.0933 - val_accuracy: 0.9582\nEpoch 607/1000\n1523/1523 [==============================] - 1s 617us/step - loss: 0.0949 - accuracy: 0.9581 - val_loss: 0.0937 - val_accuracy: 0.9579\nEpoch 608/1000\n1523/1523 [==============================] - 1s 683us/step - loss: 0.0924 - accuracy: 0.9590 - val_loss: 0.0921 - val_accuracy: 0.9600\nEpoch 609/1000\n1523/1523 [==============================] - 1s 703us/step - loss: 0.0919 - accuracy: 0.9589 - val_loss: 0.0981 - val_accuracy: 0.9556\nEpoch 610/1000\n1523/1523 [==============================] - 1s 678us/step - loss: 0.0917 - accuracy: 0.9591 - val_loss: 0.0929 - val_accuracy: 0.9596\nEpoch 611/1000\n1523/1523 [==============================] - 1s 713us/step - loss: 0.0931 - accuracy: 0.9584 - val_loss: 0.0957 - val_accuracy: 0.9567\nEpoch 612/1000\n1523/1523 [==============================] - 1s 800us/step - loss: 0.0924 - accuracy: 0.9591 - val_loss: 0.0939 - val_accuracy: 0.9591\nEpoch 613/1000\n1523/1523 [==============================] - 1s 620us/step - loss: 0.0932 - accuracy: 0.9582 - val_loss: 0.0939 - val_accuracy: 0.9588\nEpoch 614/1000\n1523/1523 [==============================] - 1s 652us/step - loss: 0.0928 - accuracy: 0.9588 - val_loss: 0.0931 - val_accuracy: 0.9590\nEpoch 615/1000\n1523/1523 [==============================] - 1s 682us/step - loss: 0.0929 - accuracy: 0.9587 - val_loss: 0.0941 - val_accuracy: 0.9599\n\nEpoch 00615: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\nEpoch 616/1000\n1523/1523 [==============================] - 1s 620us/step - loss: 0.0933 - accuracy: 0.9587 - val_loss: 0.0975 - val_accuracy: 0.9567\nEpoch 617/1000\n1523/1523 [==============================] - 1s 768us/step - loss: 0.0915 - accuracy: 0.9597 - val_loss: 0.0954 - val_accuracy: 0.9574\nEpoch 618/1000\n1523/1523 [==============================] - 1s 649us/step - loss: 0.0928 - accuracy: 0.9585 - val_loss: 0.0931 - val_accuracy: 0.9588\nEpoch 619/1000\n1523/1523 [==============================] - 1s 624us/step - loss: 0.0900 - accuracy: 0.9601 - val_loss: 0.0939 - val_accuracy: 0.9586\nEpoch 620/1000\n1523/1523 [==============================] - 1s 655us/step - loss: 0.0926 - accuracy: 0.9589 - val_loss: 0.0956 - val_accuracy: 0.9598\nEpoch 621/1000\n1523/1523 [==============================] - 1s 653us/step - loss: 0.0920 - accuracy: 0.9593 - val_loss: 0.0939 - val_accuracy: 0.9591\nEpoch 622/1000\n1523/1523 [==============================] - 1s 600us/step - loss: 0.0920 - accuracy: 0.9588 - val_loss: 0.0936 - val_accuracy: 0.9583\nEpoch 623/1000\n1523/1523 [==============================] - 1s 603us/step - loss: 0.0917 - accuracy: 0.9588 - val_loss: 0.0924 - val_accuracy: 0.9594\nEpoch 624/1000\n1523/1523 [==============================] - 1s 586us/step - loss: 0.0926 - accuracy: 0.9587 - val_loss: 0.0953 - val_accuracy: 0.9579\nEpoch 625/1000\n1523/1523 [==============================] - 1s 737us/step - loss: 0.0911 - accuracy: 0.9593 - val_loss: 0.0940 - val_accuracy: 0.9583\nEpoch 626/1000\n1523/1523 [==============================] - 1s 677us/step - loss: 0.0910 - accuracy: 0.9594 - val_loss: 0.0925 - val_accuracy: 0.9587\nRestoring model weights from the end of the best epoch\nEpoch 00626: early stopping\n"}]}]}